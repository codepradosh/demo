#!/usr/bin/env python3
"""
COMPREHENSIVE CSV Cleaner
Removes:
1. Rows where Cluster Group is blank (but incident_number is valid INC)
2. Garbage rows (ARCHIVELOG, CreateOraObject, etc)
"""

import pandas as pd
import sys

if len(sys.argv) < 3:
    print("Usage: python clean_all.py input.csv output.csv")
    sys.exit(1)

input_file = sys.argv[1]
output_file = sys.argv[2]

print("=" * 70)
print("ðŸ§¹ COMPREHENSIVE CSV CLEANER")
print("=" * 70)
print(f"Input:  {input_file}")
print(f"Output: {output_file}")

# Read CSV
print("\nðŸ“– Loading CSV...")
df = pd.read_csv(input_file, low_memory=False)
initial_rows = len(df)
print(f"   Loaded {initial_rows:,} rows")

# Find columns
cluster_col = None
for col in df.columns:
    if 'cluster' in col.lower():
        cluster_col = col
        break

print(f"\nðŸ” Cluster Group column: {cluster_col}")

# === STEP 1: Remove rows with blank Cluster Group ===
print("\n" + "=" * 50)
print("STEP 1: Remove BLANK Cluster Group rows")
print("=" * 50)

if cluster_col:
    # Identify blanks (NaN, empty string, 'nan' string)
    blank_mask = (
        df[cluster_col].isna() | 
        (df[cluster_col].astype(str).str.strip() == '') |
        (df[cluster_col].astype(str).str.lower() == 'nan')
    )
    blank_count = blank_mask.sum()
    print(f"   Found {blank_count:,} rows with blank Cluster Group")
    
    if blank_count > 0:
        blank_df = df[blank_mask]
        print("\n   Sample INC numbers with blank Cluster Group:")
        for idx in blank_df.head(10).index:
            inc = df.loc[idx, 'incident_number'] if 'incident_number' in df.columns else 'N/A'
            print(f"      {inc}")
    
    df = df[~blank_mask].copy()
    print(f"\n   âœ… Removed {blank_count:,} blank rows")
    print(f"   Remaining: {len(df):,} rows")

# === STEP 2: Remove garbage rows (non-INC incident_number) ===
print("\n" + "=" * 50)
print("STEP 2: Remove GARBAGE rows (invalid incident_number)")
print("=" * 50)

if 'incident_number' in df.columns:
    # Valid = starts with INC
    def is_valid_inc(val):
        if pd.isna(val):
            return False
        return str(val).strip().startswith('INC')
    
    valid_mask = df['incident_number'].apply(is_valid_inc)
    garbage_count = (~valid_mask).sum()
    print(f"   Found {garbage_count:,} garbage rows (not starting with INC)")
    
    if garbage_count > 0:
        garbage_df = df[~valid_mask]
        print("\n   Sample garbage incident_numbers:")
        for idx in garbage_df.head(15).index:
            inc = df.loc[idx, 'incident_number']
            print(f"      '{str(inc)[:60]}'")
    
    df = df[valid_mask].copy()
    print(f"\n   âœ… Removed {garbage_count:,} garbage rows")
    print(f"   Remaining: {len(df):,} rows")

# === FINAL SUMMARY ===
final_rows = len(df)
total_removed = initial_rows - final_rows

# Verify no blanks remain
print("\n" + "=" * 50)
print("VERIFICATION")
print("=" * 50)
if cluster_col:
    remaining_blanks = df[cluster_col].isna().sum() + (df[cluster_col].astype(str).str.strip() == '').sum()
    print(f"   Remaining blank Cluster Groups: {remaining_blanks}")

# Save
print(f"\nðŸ’¾ Saving to {output_file}...")
df.to_csv(output_file, index=False, encoding='utf-8')

print("\n" + "=" * 70)
print("ðŸ“Š FINAL SUMMARY")
print("=" * 70)
print(f"   Original rows:  {initial_rows:,}")
print(f"   Total removed:  {total_removed:,}")
print(f"   Final rows:     {final_rows:,}")
print("\nâœ… DONE! Open the cleaned file in Excel for your pivot table.")
